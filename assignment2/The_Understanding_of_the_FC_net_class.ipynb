{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The_Understanding_of_the_FC-net_class.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGHDjrFv4APsD97Rnptcv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/cs231n/blob/master/assignment2/The_Understanding_of_the_FC_net_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Wlsp3PrgYZ",
        "colab_type": "text"
      },
      "source": [
        "## 0. assignment2 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebwePTvZraou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5be6ac25-cd6e-4b1e-ea17-22605e848a55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
        "FOLDERNAME = 'Colab Notebooks/cs231n/assignments/assignment2'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# this downloads the CIFAR-10 dataset to your Drive\n",
        "# if it doesn't already exist.\n",
        "%cd drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
        "!bash get_datasets.sh\n",
        "%cd /content"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/cs231n/assignments/assignment2/cs231n/datasets\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz8fgnoTtPlm",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "f73df4c5-4779-46c3-da83-6ea3c045047b"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() # 파일 업로드 기능 실행\n",
        "\n",
        "for fn in uploaded.keys(): # 업로드된 파일 정보 출력\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-522fde7f-b854-4091-a470-8a2ba90938b1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-522fde7f-b854-4091-a470-8a2ba90938b1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving st0.png to st0.png\n",
            "User uploaded file \"st0.png\" with length 8621 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcYZdJYdtg5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNNwnYOamP97",
        "colab_type": "text"
      },
      "source": [
        "## 1. 전연결 신경망 in cs231n assignment2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfHLPF11mUzS",
        "colab_type": "text"
      },
      "source": [
        "임의의 개수의 은닉층, ReLU 활성화, 소프트맥스 손실 함수, 드롭아웃과 배치/레이어 정규화를 가진 전연결 신경망을 코딩해보자. \n",
        "  \n",
        "  (affine - [batch/layer norm] - relu - [dropout]) x (L - 1) - affine - softmax  \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUtnrcADmuHY",
        "colab_type": "text"
      },
      "source": [
        "여기서 배치/레이어 정규화와 드롭아웃은 선택적이다. 학습 가능한 모수는 self.params 딕셔너리에 저장하고, solver class를 사용하여 이것을 학습시켜라."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q5Ob6qJm7kz",
        "colab_type": "text"
      },
      "source": [
        "**Inputs:**  \n",
        "- **hidden_dims:** A list of integers giving the size of each hidden layer.\n",
        "- **input_dim:** An integer giving the size of the input.\n",
        "- **num_classes:** An integer giving the number of classes to classify.\n",
        "- **dropout:** giving dropout strength, 0~1의 스칼라. If dropout=1 then dropout 사용 x.\n",
        "\n",
        "- **normalization**: What type of normalization the network should use. Valid values are \"batchnorm\", \"layernorm\", or None for no normalization (the default).\n",
        "- **reg**: Scalar giving L2 regularization strength.\n",
        "-**weight_scale**:  가중치의 랜덤 초기화의 표준 편차를 제공해주는 스칼라\n",
        "- **dtype**:  A numpy datatype object; all computations will be performed using this datatype. float32 is faster but less accurate, so you should use float64 for numeric gradient checking.\n",
        "\n",
        "- **seed**: If seed = None, then this random seed ==pass==> dropout layers. This will make the dropout layers deteriminstic, so we can gradient check the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k14MmHUFsxXv",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 스택stack  \n",
        "  \n",
        "  필자는 이 글을 작성하고 있는 현 시점에서 스택을 처음 써본다. 그래서 간략히 이것에 대해 알아본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql3wpJVptInL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "36a8a774-8925-461b-b5f2-d7602462f2d4"
      },
      "source": [
        "Image('st0.png')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yQzKiWotn1j",
        "colab_type": "text"
      },
      "source": [
        "스택은 마지막에 들어간 것이 처음으로 나온다. 이른바, 후입선출이다. 스택의 마지막 항에 어떤 요소를 넣을 때, push를 사용하고, 그것을 뺄 때는 pop을 사용한다. is_empty를 통해 스택이 비어있는지를 확인한다. 아래 코드에서 사용할 hstack 에 대해 알아보자. 이것은 스택을 횡렬로 쌓는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW8NPHeDuGRs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "eca96dde-f0e2-4453-bd43-6744f38922e2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "mat1 = np.random.randn(2,3)\n",
        "mat2 = np.random.randn(2,3)\n",
        "\n",
        "print(mat1,'\\n\\n',mat2,'\\n\\n')\n",
        "print(np.hstack((mat1,mat2)))\n",
        "\n",
        "dims = np.hstack((2,3,4))\n",
        "print(dims)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.99535561 -1.06874509 -0.97035768]\n",
            " [ 0.55826868  2.27020101 -0.98206229]] \n",
            "\n",
            " [[ 0.85231377 -0.09285112 -0.2800965 ]\n",
            " [-0.4065982  -0.74166892 -1.08910321]] \n",
            "\n",
            "\n",
            "[[ 1.99535561 -1.06874509 -0.97035768  0.85231377 -0.09285112 -0.2800965 ]\n",
            " [ 0.55826868  2.27020101 -0.98206229 -0.4065982  -0.74166892 -1.08910321]]\n",
            "[2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNOLRDvzmL7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "65e14d35-cedb-4a3e-c472-f66a2b3aa84c"
      },
      "source": [
        "from builtins import range\n",
        "from builtins import object\n",
        "import numpy as np\n",
        "\n",
        "from cs231n.layers import *\n",
        "from cs231n.layer_utils import *\n",
        "\n",
        "\n",
        "\n",
        "class FullyConnectedNet(object):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dims,\n",
        "        input_dim=3 * 32 * 32,\n",
        "        num_classes=10,\n",
        "        dropout=1,\n",
        "        normalization=None,\n",
        "        reg=0.0,\n",
        "        weight_scale=1e-2,\n",
        "        dtype=np.float32,\n",
        "        seed=None,\n",
        "        use_batchnorm=False\n",
        "    ):\n",
        "\n",
        "\n",
        "        self.use_batchnorm = use_batchnorm\n",
        "        self.normalization = normalization\n",
        "        self.use_dropout = dropout != 1\n",
        "        self.reg = reg\n",
        "        self.num_layers = 1 + len(hidden_dims)\n",
        "        self.dtype = dtype\n",
        "        self.params = {}\n",
        "\n",
        "        \"\"\" \n",
        "        모든 값을 self.params 딕셔너리에 저장하면서, 연결망의 모수를 초기화하라. 가중치는 표준 정규 분포로\n",
        "        초기화되어야 하고, bias는 0으로 초기화되어야 한다.\n",
        "\n",
        "        배치 정규화 사용 시, 스케일, 쉬프트 모수를 감마, 베타에 저장하라. 스케일 모수는 1로 쉬프트 모수는 0으로\n",
        "        초기화 하라.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        dims = np.hstack((input_dim, hidden_dims, num_classes)) # 차원을 스택을 이용해서 만든 것 뿐이다.\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            self.params['W%d' % (i + 1)] = weight_scale * np.random.randn(dims[i], dims[i+1])\n",
        "            self.params['b%d' % (i + 1)] = np.zeros(dims[i+1])\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "\n",
        "        \"\"\"\n",
        "        드롭아웃 사용 시, 우리는 layer가 드롭아웃_확률과 그 mode(학습/테스트)를 알게 하기 위해\n",
        "        <드롭아웃_모수 딕셔너리>를 --> <각 드롭아웃 레이어>로 보낼 필요가 있다.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        self.dropout_param = {} # dropout 모수 초기화.\n",
        "        if self.use_dropout:\n",
        "            self.dropout_param = {\"mode\": \"train\", \"p\": dropout}\n",
        "            if seed is not None:\n",
        "                self.dropout_param[\"seed\"] = seed\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        배치 정규화를 가지고서, 우리는 평균, 분산을 추적할 필요가 있고, 따라서 특별한 bn_param 객체를\n",
        "        각 배치 정규화 layer로 보낼 필요가 있다. 당신은 self.bn_params[0]를 1st 배치 정규화 층의\n",
        "        순전파로 보낼 필요가 있고, self.bn_params[1]를 2nd 배치 정규화의 순전파로 보낼 필요가 있다.\n",
        "        \"\"\"\n",
        "\n",
        "        self.bn_params = []\n",
        "        if self.normalization == \"batchnorm\":\n",
        "            self.bn_params = [{\"mode\": \"train\"} for i in range(self.num_layers - 1)]\n",
        "        if self.normalization == \"layernorm\":\n",
        "            self.bn_params = [{} for i in range(self.num_layers - 1)]\n",
        "\n",
        "        # Cast all parameters to the correct datatype\n",
        "        for k, v in self.params.items():\n",
        "            self.params[k] = v.astype(dtype)\n",
        "\n",
        "    def loss(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Compute loss and gradient for the fully-connected net.\n",
        "\n",
        "        Input / output: Same as TwoLayerNet above.\n",
        "        \"\"\"\n",
        "        X = X.astype(self.dtype) # 형변환\n",
        "        mode = \"test\" if y is None else \"train\"\n",
        "\n",
        "        # Set train/test mode for batchnorm params and dropout param since they\n",
        "        # behave differently during training and testing.\n",
        "        if self.use_dropout:\n",
        "            self.dropout_param[\"mode\"] = mode\n",
        "        if self.normalization == \"batchnorm\":\n",
        "            for bn_param in self.bn_params:\n",
        "                bn_param[\"mode\"] = mode\n",
        "        scores = None\n",
        "\n",
        "        \"\"\"\n",
        "        (1) X의 클래스 스코어 계산하고 그것을 스코어 변수에 저장하면서, fcnet의 순전파 수행\n",
        "        (2) 드롭아웃 사용 시, self.dropout_param을 각 드롭아웃 순전파에 통과시켜야\n",
        "        (3) 배치 정규화 사용시, self.bn_params[0]을 첫 번째 배치 정규화 레이어의 순전파에 통과시키고,\n",
        "        self.bn_params[1]을 두번째 배치 정규화 레이어에 통과 시켜 ... \n",
        "        \"\"\"\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        hidden_num = self.num_layers - 1\n",
        "        scores = X\n",
        "        cache_history = []\n",
        "        L2reg = 0\n",
        "        for i in range(hidden_num):\n",
        "            if self.use_batchnorm:\n",
        "                scores, cache = affine_bn_relu_forward(scores,\n",
        "                                                      self.params['W%d' % (i + 1)],\n",
        "                                                      self.params['b%d' % (i + 1)],\n",
        "                                                      self.params['gamma%d' % (i + 1)],\n",
        "                                                      self.params['beta%d' % (i + 1)],\n",
        "                                                      self.bn_params[i])\n",
        "            else:\n",
        "                scores, cache = affine_relu_forward(scores, self.params['W%d' % (i + 1)],\n",
        "                                                            self.params['b%d' % (i + 1)])\n",
        "            cache_history.append(cache)\n",
        "            if self.use_dropout:\n",
        "                scores, cache = dropout_forward(scores, self.dropout_param)\n",
        "                cache_history.append(cache)\n",
        "            L2reg += np.sum(self.params['W%d' % (i + 1)] ** 2)\n",
        "        i += 1\n",
        "        scores, cache = affine_forward(scores, self.params['W%d' % (i + 1)],\n",
        "                                               self.params['b%d' % (i + 1)])\n",
        "        cache_history.append(cache)\n",
        "        L2reg += np.sum(self.params['W%d' % (i + 1)] ** 2)\n",
        "        L2reg *= 0.5 * self.reg\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                             END OF YOUR CODE                             #\n",
        "        ############################################################################\n",
        "\n",
        "        # If test mode return early\n",
        "        if mode == \"test\":\n",
        "            return scores\n",
        "\n",
        "        loss, grads = 0.0, {}\n",
        "\n",
        "        \"\"\"\n",
        "        전연결망의 역전파를 수행하라. 손실 변수는 loss에 그래디언트는 grads 딕셔너리에 넣어라. \n",
        "        소프트맥스를 사용하여 데이터를 계산하고 grads[k]가 self.params[k]의 grads에 성립하게 만들어라.\n",
        "        L2정규화도 해라.\n",
        "        \n",
        "        배치/레이어 정규화 시, 파라미터 정규화할 필요 없다.\n",
        "        \n",
        "        주의: L2 정규화는 0.5로 써라.        \"\"\"\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        loss, dout = softmax_loss(scores, y)\n",
        "        loss += L2reg\n",
        "\n",
        "        dout, grads['W%d' % (i + 1)], grads['b%d' % (i + 1)] = affine_backward(dout, cache_history.pop())\n",
        "        grads['W%d' % (i + 1)] += self.reg * self.params['W%d' % (i + 1)]\n",
        "        i -= 1\n",
        "        while i >= 0:\n",
        "            if self.use_dropout:\n",
        "                dout = dropout_backward(dout, cache_history.pop())\n",
        "            if self.use_batchnorm:\n",
        "                dout, grads['W%d' % (i + 1)], grads['b%d' % (i + 1)], grads['gamma%d' % (i + 1)], grads['beta%d' % (i + 1)] = affine_bn_relu_backward(dout, cache_history.pop())\n",
        "            else:\n",
        "                dout, grads['W%d' % (i + 1)], grads['b%d' % (i + 1)] = affine_relu_backward(dout, cache_history.pop())\n",
        "            grads['W%d' % (i + 1)] += self.reg * self.params['W%d' % (i + 1)]\n",
        "            i -= 1\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        return loss, grads"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========== You can safely ignore the message below if you are NOT working on ConvolutionalNetworks.ipynb ===========\n",
            "\tYou will need to compile a Cython extension for a portion of this assignment.\n",
            "\tThe instructions to do this will be given in a section of the notebook below.\n",
            "\tThere will be an option for Colab users and another for Jupyter (local) users.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7K-2Temqsrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93dd9df1-4546-4cc5-fb7d-6a5d194663b7"
      },
      "source": [
        "import numpy as np\n",
        "a = np.random.randn(3,2)\n",
        "b = np. random.randn(3,2)\n",
        "\n",
        "c= np.hstack((a,b))\n",
        "print(c.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}